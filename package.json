{
  "name": "voice-prompt",
  "displayName": "Voice Typing",
  "description": "Capture voice, route command intent, and inject into VS Code / Cursor input.",
  "version": "0.2.1",
  "publisher": "qingy-wu",
  "repository": {
    "type": "git",
    "url": "https://github.com/bread22/voice-typing.git"
  },
  "homepage": "https://github.com/bread22/voice-typing#readme",
  "bugs": {
    "url": "https://github.com/bread22/voice-typing/issues"
  },
  "license": "MIT",
  "engines": {
    "vscode": "^1.90.0"
  },
  "keywords": [
    "voice",
    "speech",
    "dictation",
    "whisper",
    "microphone",
    "accessibility",
    "transcription",
    "stt"
  ],
  "categories": [
    "Other",
    "Machine Learning"
  ],
  "galleryBanner": {
    "color": "#1a1a2e",
    "theme": "dark"
  },
  "icon": "icon.png",
  "main": "./dist/extension.js",
  "activationEvents": [
    "onCommand:voicePrompt.startRecording",
    "onStartupFinished"
  ],
  "contributes": {
    "commands": [
      {
        "command": "voicePrompt.startRecording",
        "title": "Voice Prompt: Start Recording"
      }
    ],
    "keybindings": [
      {
        "command": "voicePrompt.startRecording",
        "key": "alt+v",
        "when": ""
      }
    ],
    "configuration": {
      "title": "Voice Prompt",
      "properties": {
        "voicePrompt.stt.provider": {
          "type": "string",
          "default": "whisper-cpp",
          "enum": ["whisper-cpp", "http"],
          "enumDescriptions": [
            "Local whisper-cpp CLI (recommended, no server needed)",
            "HTTP endpoint (for custom STT servers)"
          ],
          "description": "Speech-to-text provider."
        },
        "voicePrompt.stt.model": {
          "type": "string",
          "default": "base",
          "enum": ["tiny.en", "tiny", "base.en", "base", "small.en", "small"],
          "enumDescriptions": [
            "English-only, ~75 MB, fastest",
            "Multilingual, ~75 MB, fast",
            "English-only, ~142 MB, good accuracy",
            "Multilingual, ~142 MB, good accuracy (recommended for multi-language)",
            "English-only, ~466 MB, best English accuracy",
            "Multilingual, ~466 MB, best multilingual accuracy"
          ],
          "description": "Whisper model size. Models without '.en' suffix support all languages."
        },
        "voicePrompt.stt.whisperCppPath": {
          "type": "string",
          "default": "",
          "description": "Path to whisper-cpp binary. Leave empty to auto-detect from PATH."
        },
        "voicePrompt.stt.modelPath": {
          "type": "string",
          "default": "",
          "description": "Path to GGML model file. Leave empty to auto-download."
        },
        "voicePrompt.stt.httpEndpoint": {
          "type": "string",
          "default": "http://127.0.0.1:8765/transcribe",
          "description": "HTTP STT endpoint (used when provider is 'http')."
        },
        "voicePrompt.stt.timeoutMs": {
          "type": "number",
          "default": 30000,
          "minimum": 5000,
          "maximum": 120000,
          "description": "STT timeout in milliseconds."
        },
        "voicePrompt.stt.language": {
          "type": "string",
          "default": "auto",
          "description": "Language code for speech recognition. Use 'auto' to detect automatically, or a specific code like 'en', 'zh', 'ja', 'ko', etc."
        },
        "voicePrompt.command.provider": {
          "type": "string",
          "default": "none",
          "enum": ["chatgpt", "none"],
          "enumDescriptions": [
            "ChatGPT subscription token from ~/.codex/auth.json",
            "Disable command routing layer"
          ],
          "description": "Command layer provider."
        },
        "voicePrompt.command.chatgptModel": {
          "type": "string",
          "default": "gpt-5-codex-mini",
          "description": "ChatGPT command layer model identifier."
        },
        "voicePrompt.command.chatgptBaseUrl": {
          "type": "string",
          "default": "https://chatgpt.com/backend-api/codex/responses",
          "description": "ChatGPT command layer endpoint (Codex-compatible)."
        },
        "voicePrompt.command.timeoutMs": {
          "type": "number",
          "default": 20000,
          "minimum": 1000,
          "maximum": 120000,
          "description": "Command layer request timeout in milliseconds."
        },
        "voicePrompt.previewBeforeInsert": {
          "type": "boolean",
          "default": false,
          "description": "Show editable preview before insertion."
        },
        "voicePrompt.showStatusBarButton": {
          "type": "boolean",
          "default": true,
          "description": "Show status bar microphone button."
        },
        "voicePrompt.insertTrailingSpace": {
          "type": "boolean",
          "default": true,
          "description": "Append a space after inserted text for easier consecutive inputs."
        },
        "voicePrompt.vad.enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable VAD auto-end behavior."
        },
        "voicePrompt.vad.silenceMs": {
          "type": "number",
          "default": 1500,
          "minimum": 600,
          "maximum": 3000,
          "description": "Silence duration (ms) before auto-stop. Increase if speech is cut off."
        },
        "voicePrompt.vad.minSpeechMs": {
          "type": "number",
          "default": 300,
          "minimum": 100,
          "maximum": 1000,
          "description": "Minimum speech duration to accept input."
        },
        "voicePrompt.wakeWord.enabled": {
          "type": "boolean",
          "default": true,
          "description": "Enable always-on wake-word detection via openWakeWord."
        },
        "voicePrompt.wakeWord.model": {
          "type": "string",
          "default": "alexa",
          "description": "openWakeWord model name (for example: hey_jarvis, alexa, hey_mycroft, hey_rhasspy)."
        },
        "voicePrompt.wakeWord.threshold": {
          "type": "number",
          "default": 0.5,
          "minimum": 0.1,
          "maximum": 0.99,
          "description": "Detection threshold for the wake-word score."
        },
        "voicePrompt.wakeWord.cooldownMs": {
          "type": "number",
          "default": 4000,
          "minimum": 1000,
          "maximum": 15000,
          "description": "Minimum gap between wake triggers in milliseconds."
        },
        "voicePrompt.wakeWord.pythonPath": {
          "type": "string",
          "default": "python3",
          "description": "Python executable used to run openWakeWord (for example: python3, python, /usr/bin/python3)."
        }
      }
    }
  },
  "scripts": {
    "build": "tsc -p .",
    "bundle": "node esbuild.mjs --production",
    "bundle:dev": "node esbuild.mjs",
    "package": "npm run bundle && npx vsce package --no-dependencies --skip-license --allow-missing-repository",
    "dev": "node esbuild.mjs && npx vsce package --no-dependencies --skip-license --allow-missing-repository -o voice-prompt-dev.vsix",
    "watch": "tsc -w -p .",
    "test": "npm run build && node test/runTests.js"
  },
  "devDependencies": {
    "@types/node": "^22.13.10",
    "@types/vscode": "^1.90.0",
    "@vscode/vsce": "^2.32.0",
    "esbuild": "^0.25.0",
    "typescript": "^5.8.2"
  },
  "dependencies": {
    "openai": "^5.23.0",
    "undici": "^7.5.0"
  }
}
